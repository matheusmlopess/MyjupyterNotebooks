{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1606419752315,
     "user": {
      "displayName": "Matheus lopes",
      "photoUrl": "",
      "userId": "10384866493879646145"
     },
     "user_tz": 180
    },
    "id": "xs8SN0jO1D1D",
    "outputId": "dcb9e175-ba9a-4bb4-f493-b24763aaa38d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Overwriting /content/drive/MyDrive/Projetos/Codes/modules_colab/__init__.py\n",
      "Overwriting /content/drive/MyDrive/Projetos/Codes/my_modules/__init__.py\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount(\"/content/drive\")\n",
    "%run \"/content/drive/MyDrive/functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1606419788825,
     "user": {
      "displayName": "Matheus lopes",
      "photoUrl": "",
      "userId": "10384866493879646145"
     },
     "user_tz": 180
    },
    "id": "KZhSNqmNDluW",
    "outputId": "52fcdb8d-7108-4e61-affe-d943c59528bf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Function from a samemememeee'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import my_modules\n",
    "my_modules.okayy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqkjrrPctO29"
   },
   "source": [
    "#What is computer vision?\n",
    "\n",
    "> So what can you see in this image? Instantly, you know it's a street photo. You can see people, parked cars, shops, hotels and buildings. If you take a closer look, you can also see signs, lamps, windows and so forth. The observations you make are all based on the level of detail you need to summarize from the image. Now think about more difficult questions like, how many people are in the image? What are they doing? Where is this place? Maybe you can come up with some other questions as well.\n",
    "\n",
    "Digital images or videos for various applications. The [inaudible] of computer vision is creating software systems that can process, analyze and make inferences from digital images. The goal is to extract the numerical or symbolic information from image inputs. Computer vision is often considered a sub field of artificial intelligence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuBaHqPOtQft"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBQLecmJuDdF"
   },
   "source": [
    "##computer vision tasks:\n",
    "\n",
    "The field of computer vision emerged in the 1960s. It originated in universities that were building on the early success of AI which began a decade earlier\n",
    "\n",
    "They established that processing in the visual cortex of the brain starts with neurons that respond to simple structures like edges before those that respond to complex patterns\n",
    "\n",
    "\n",
    " cells that could hierarchically recognize patterns in digital images. You call this artificial framework the neurocognition. This networks are now called convolutional neural networks or CNN's\n",
    "\n",
    " in 2012, there was a resurgence due to the availability of more powerful computer resources, hardware accelerators like GPUs and large datasets thanks to the Internet. The subfield of deep learning grew and dominated accuracy benchmarks for computer vision tasks.\n",
    " \n",
    "  Now, all the state of the art resulting computer vision are achieved using deep learning. Several computer vision tasks are tackled with deep learning and they differ in terms of the information they attempt to extract from digital images. In other words, they answer different questions about an image.\n",
    "  \n",
    "  - The first task is image classification. Here's a classic example. Given this picture of a dog, imagine you'd like to ask, what class of image is it? A model solve this task by providing a level output that corresponds to the class dog when fed the image input.\n",
    "> Image classification models are trained using images annotated with pre-specified classes and they learn to associate those class labels to the images. \n",
    "\n",
    "  - The object detection task tackles this problem. The task localizes the objects with boxes on the input image and for each localization it classifies the object in the box. You can see that the object detection model has bounding boxes around the three main objects in the image; two dogs and one cat. Also, the model assigns a name to each box.\n",
    "\n",
    "  > This is essentially an upgraded version of image classification. It answers questions a bit more realistically since a typical image usually contains more than one object. objects are usually not shaped like rectangular boxes. An improved question might be, where is the boundary for every object? This becomes the task of semantic segmentation.\n",
    "\n",
    "  -  semantic segmentation: Semantic segmentation generates a mask on objects so that every object has a boundary and is separated from the background. This requires predicting a class for every pixel in the image, yet you can see that the two dogs are still in the same mask. Semantic segmentation can tell objects from the background and it can also tell objects in one class from objects in a different class. For objects in the same class like the two dogs, it cannot tell the difference. \n",
    "> Instance segmentation generates masks for segments or objects in the image as well as separate different instances even if they are in the same class. \n",
    "\n",
    "  -  Pose estimation \n",
    "\n",
    "\n",
    "    Next, simple algorithms run faster. If you don't need fine level information, you should not choose an overly-complex model. Another main learning outcome you'll gain from this course is how to choose the most suitable model for each task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiGQmgO1vh0y"
   },
   "source": [
    "# FrameWorks\n",
    "\n",
    "<pre>\n",
    "<b> A framework provides the software tool \n",
    " for building and training neural network models\n",
    " vision and other applications</b>\n",
    "</pre>\n",
    "\n",
    "> Deep Learning Frameworks Compared:\n",
    "\n",
    "> MxNet\n",
    ">>\n",
    "~~~~\n",
    " MXNet is another popular Deep Learning framework. Founded by the Apache Software Foundation,\n",
    " MXNet supports a wide range of languages like JavaScript, Python, and C++. MXNet is also \n",
    " supported by Amazon Web Services to build deep learning models.\n",
    "~~~~\n",
    "\n",
    "> TensorFlow\n",
    ">>\n",
    "~~~~\n",
    " TensorFlow is the most famous deep learning library around. It is one of the most efficient \n",
    " open-source libraries to work with.TensorFlow powers a lot of useful applications including Uber\n",
    " ,Dropbox, and Airbnb.\n",
    "~~~~\n",
    "\n",
    "> Microsoft CNTK\n",
    ">>\n",
    "~~~~\n",
    " Large companies usually use Microsoft Cognitive Toolkit (CNTK) to build deep learning models.\n",
    " CNTK is an open-source framework. It illustrates neural networks in the form of directed graphs by \n",
    " using a sequence of computational steps. written using C++, but supports C#, Python, C++, and Java.\n",
    "~~~~\n",
    "\n",
    "> DL4j\n",
    ">>\n",
    "~~~~\n",
    " DeepLearning4j is an excellent framework if your main programming language is Java. It is a  \n",
    " commercial-grade, open-source, distributed deep-learning library.\n",
    "~~~~\n",
    "\n",
    "> PyTorch\n",
    ">>\n",
    "~~~~\n",
    " Image Recognition, Natural Language Processing, and Reinforcement Learning are some of the many \n",
    " areas in which PyTorch shines. It is also used in research by universities like Oxford and \n",
    " organizations like IBM.Â´\n",
    "~~~~\n",
    "\n",
    "\n",
    ">[Source](https://www.freecodecamp.org/news/deep-learning-frameworks-compared-mxnet-vs-tensorflow-vs-dl4j-vs-pytorch/#:~:text=Compared%20to%20TensorFlow%2C%20MXNet%20has,not%20as%20popular%20as%20Tensorflow. \"comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRMb6QJZxcn7"
   },
   "source": [
    "### XMnet \n",
    "\n",
    "    MXNet is a deep learning framework that provides the software tool\n",
    "    for building and training neural network models for computer\n",
    "    vision and other applications.\n",
    ">MXNet originated as a project by the **Distributed Machine** Learning Community known as DMLC.\n",
    "\n",
    "The goal was to create open-source software tools for machine learning applications.\n",
    "\n",
    "> XGBoost is an optimized distributed library that implements gradient boosted decision tree models\n",
    "\n",
    "> TVM is a deep learning compiler, and MXNet is the subject of this video. In November 2016, Amazon announced MXNet as the company's deep learning framework of choice.\n",
    "\n",
    "MxNet supports Python, R, Perl Java, Julia, Scala, Clojure and C++ as front end languages. To ensure reliable performance, it's back end, the asynchronous MXNet engine is implemented in C++.\n",
    "\n",
    "MXNet has all these features and the benefit of a tightly integrated ecosystem.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av-oJmykym6z"
   },
   "source": [
    "#### Ecosystem\n",
    "\n",
    "- GluonCV is a toolkit for computer vision applications, that makes it easy to use state of the art pre-trained models for specific computer vision tasks.\n",
    "\n",
    "- GluonNLP is similar to GluonCV, and it's the toolkit counterpart for natural language processing. It has translation models, a variety of pre-trained language models, embeddings, and general utility tools for language data.\n",
    "\n",
    "- Keras is a well-known front end deep learning interface. Now, you can choose to use MXNet as its back end with Keras MXNet. MXBoard helps users visualize the training process, and diagnose possible issues and bugs at an early stage.\n",
    "\n",
    "-  The model server is an open-source tool developed by AWS, for seven models exported from MXNet, or the Open Neural Network Exchange format known as ONNX. \n",
    "> Open Neural Network Exchange format known as ONNX\n",
    "\n",
    "- TensorRT is a deep learning inference optimizer by NVIDIA, for high-throughput inference on deep neural networks. It is tightly integrated with MXNet library, and can be used by MXNet models.\n",
    "\n",
    "- TVM mentioned earlier, is an open-source tool that helps model deployment on various hardware environments, while achieving impressive acceleration during inference.\n",
    "\n",
    "\n",
    "ONNX is an ecosystem for interchangeable AI models. MXNet has significant support for converting MXNet models from and to the ONNX open format.\n",
    "\n",
    "This rich ecosystem of tools and libraries make MXNet a versatile deep learning framework.\n",
    "\n",
    "    Open Neural Network Exchange format known as ONNX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OaDgsY1zp5i"
   },
   "source": [
    "#GluonCV\n",
    "\n",
    "'''\n",
    "GluonCV, an open source, flexible, easy to use computer vision toolkit.\n",
    "\n",
    "- Typically, you choose a tool based on the scenario and task. However, many open source tools have a few common issues. First, the tool might not have the models you need for your specific task. \n",
    "\n",
    "\n",
    ">`Many computer vision toolkits are not comprehensive and only contain models for a single task, such as image classification or object detection. In fact, some tools only implement a single model.`\n",
    "\n",
    "\n",
    "    if you have a complex process that requires different models for different steps, \n",
    "    you might have to cobble together models from different sources and toolkits. \n",
    "    This introduces additional, possibly even significant work overhead. \n",
    "\n",
    "> This introduces additional, possibly even significant work overhead. \n",
    ">>In addition, you might encounter non-trivial differences in installation and configuration, data pre-processing, model performance, or programming languages.\n",
    "\n",
    "       In the worst case, this might conflict across tools. Second, \n",
    "       some open source implementations are incorrect. \n",
    "\n",
    "For instance, the research paper might only vaguely describe the model specification or the tools model implementation might be at an early stage and has not been rigorously tested.\n",
    "\n",
    ">>> Third, individual developers often give up on the maintenance of their open source implementations. Repository sometimes attract attention and significant use early on, but over time, they fail to receive followup maintenance or incremental improvements. \n",
    "\n",
    "\n",
    "`Finally, model deployment must be considered. For an industrial or commercial applications, model are expected to work on various hardware configurations like GPUs, CPUs or Edge devices. In many vision toolkits, the gap exists between model experimentation and applicable model deployment.`\n",
    "\n",
    "\n",
    "To address this common issues, AWS scientists created GluonCV, an open source toolkit for computer vision. GluonCV provides models for different tasks, including image classification, object deduction, semantic segmentation, instance segmentation, and pose estimation. You can learn to use a trend model for one task and easily transfer the knowledge to other tasks. \n",
    "\n",
    ">In addition, GluonCV provides vetted implementations for state-of-the-art computer vision models, sometimes a better accuracy than the original paper or other open source implementations.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA9fXAy2IpE2"
   },
   "source": [
    "# Nova seÃ§Ã£o\n",
    "\n",
    "[Serialization](https://www.intechopen.com/books/introduction-to-data-science-and-machine-learning/serialization-in-object-oriented-programming-languages)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9FJsEPLEbfuU+8sdf27if",
   "collapsed_sections": [],
   "name": "AWS_CV_Theory.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
